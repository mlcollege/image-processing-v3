{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "05-GANs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P0dH-wfiDv2L"
      },
      "source": [
        "# Generative Adversarial Networks\n",
        "\n",
        "In this notebook we will experiment with Generative Adversarial Networks for superresolution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UevhtR-ezQnX",
        "colab": {}
      },
      "source": [
        "!wget --output-document sres.zip https://drive.google.com/uc?id=1DCtjTsgO4LYweU5OnYFrj0Snnef9WLn2\n",
        "!unzip -o sres.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x6LvNkh1nmZa"
      },
      "source": [
        "Define data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zGhBaCCzDhlc",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, mode = 'L'):\n",
        "        self.mode =  mode\n",
        "        self.input_shape = None\n",
        "        self.output_shape = None\n",
        "        \n",
        "    \n",
        "    def imread(self, path):\n",
        "        return imageio.imread(path, pilmode=self.mode).astype(np.float)\n",
        "\n",
        "    def load_data(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"test\"\n",
        "\n",
        "        path = glob('./sres/{}/source/*'.format(data_type))\n",
        "\n",
        "        batch_images = np.random.choice(path, size=batch_size) if not is_testing else path\n",
        "\n",
        "        imgs_src = []\n",
        "        imgs_trg = []\n",
        "        for img_path in batch_images:\n",
        "            img_src = self.imread(img_path)\n",
        "            img_trg = self.imread(img_path.replace('source', 'target'))\n",
        "\n",
        "            img_src = np.expand_dims(img_src, axis=2) \n",
        "            img_trg = np.expand_dims(img_trg, axis=2) \n",
        "            \n",
        "            imgs_trg.append(img_trg)\n",
        "            imgs_src.append(img_src)\n",
        "\n",
        "        imgs_trg = np.array(imgs_trg) / 127.5 - 1.\n",
        "        imgs_src = np.array(imgs_src) / 127.5 - 1.\n",
        "        self.input_shape = imgs_src.shape[1:]\n",
        "        self.output_shape = imgs_trg.shape[1:]\n",
        "\n",
        "        return imgs_src, imgs_trg\n",
        "\n",
        "    def single_img(self, file_name):\n",
        "        img_src = self.imread(file_name)\n",
        "        return np.array([img_src]) / 127.5 - 1."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0ZErpIGRoY0y"
      },
      "source": [
        "Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypAmQMAdQahF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import scipy\n",
        "import datetime\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, PReLU, LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "\n",
        "class SRGAN:\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.channels = 1\n",
        "        self.width = output_size[0]\n",
        "        self.height = output_size[1]\n",
        "        self.shape = (self.height, self.width, self.channels)\n",
        "        self.input_shape = (input_size[1], input_size[0], self.channels)\n",
        "\n",
        "        # Number of residual blocks in the generator\n",
        "        self.n_residual_blocks = 16\n",
        "\n",
        "        # Number of filters in the first layer of G and D\n",
        "        self.gf = 64\n",
        "        self.df = 64\n",
        "\n",
        "        zoom = output_size[0] // input_size[0]\n",
        "        self.upsampling_levels = int(np.log(zoom)/np.log(2))\n",
        "\n",
        "\n",
        "        # Calculate output shape of D (PatchGAN)\n",
        "        patch_width = -(-self.width // 2**4)\n",
        "        patch_height = -(-self.height // 2**4)\n",
        "        self.disc_patch = (patch_height, patch_width, 1)\n",
        "\n",
        "        self.optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # We use a pre-trained VGG19 model to extract image features from the target\n",
        "        # image and the generated images and minimize the mse between them\n",
        "        self.vgg = self.get_vgg()\n",
        "\n",
        "        self.discriminator = self.get_discriminator()\n",
        "\n",
        "        self.generator = self.get_generator()\n",
        "\n",
        "        self.gan = self.get_gan(self.discriminator, self.generator)\n",
        "\n",
        "    def get_vgg(self):\n",
        "        \"\"\"\n",
        "        Builds a pre-trained VGG19 model that outputs image features extracted at the\n",
        "        third block of the model\n",
        "        \"\"\"\n",
        "        # Set outputs to outputs of last conv. layer in block 3\n",
        "        vgg19 = VGG19(include_top=False, weights=\"imagenet\")\n",
        "        #vgg19 = VGG19(input_shape=(440,512))\n",
        "\n",
        "        #vgg19.outputs = [vgg19.layers[10].output]\n",
        "\n",
        "        # Extract image features\n",
        "        vgg_input = Input(shape=self.shape)\n",
        "        a = Dense(3)(vgg_input)\n",
        "        #vgg_output = vgg19(vgg_input)\n",
        "        vgg_output = vgg19(a)\n",
        "        \n",
        "        #build the model\n",
        "        vgg = Model(inputs=vgg_input, outputs=vgg_output)\n",
        "        vgg.trainable = False\n",
        "        vgg.compile(loss='mse', optimizer=self.optimizer)\n",
        "        \n",
        "        return vgg\n",
        "\n",
        "    def get_discriminator(self):\n",
        "        \"\"\"\n",
        "        Builds the discriminator\n",
        "        \"\"\"\n",
        "\n",
        "        def d_block(layer_input, filters, strides=1, bn=True):\n",
        "            \"\"\"Discriminator layer\"\"\"\n",
        "            d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
        "            d = LeakyReLU(alpha=0.2)(d)\n",
        "            if bn:\n",
        "                d = BatchNormalization(momentum=0.8)(d)\n",
        "            return d\n",
        "\n",
        "        disc_input = Input(shape=self.shape)\n",
        "        \n",
        "        d1 = d_block(disc_input, self.df, bn=False)\n",
        "        d2 = d_block(d1, self.df, strides=2)\n",
        "        d3 = d_block(d2, self.df*2)\n",
        "        d4 = d_block(d3, self.df*2, strides=2)\n",
        "        d5 = d_block(d4, self.df*4)\n",
        "        d6 = d_block(d5, self.df*4, strides=2)\n",
        "        d7 = d_block(d6, self.df*8)\n",
        "        d8 = d_block(d7, self.df*8, strides=2)\n",
        "        d9 = Dense(self.df*16)(d8)\n",
        "        d10 = LeakyReLU(alpha=0.2)(d9)\n",
        "        \n",
        "        disc_output = Dense(1, activation='sigmoid')(d10)\n",
        "\n",
        "        discriminator = Model(inputs=disc_input, outputs=disc_output)\n",
        "        discriminator.compile(loss='binary_crossentropy',\n",
        "            optimizer=self.optimizer)\n",
        "\n",
        "        return discriminator\n",
        "\n",
        "        \n",
        "    def get_generator(self):\n",
        "        \"\"\"\n",
        "        Builds the generator\n",
        "        \"\"\"\n",
        "        def residual_block(layer_input, filters):\n",
        "            \"\"\"Residual block described in the SRGAN paper\"\"\"\n",
        "            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(layer_input)\n",
        "            d = Activation('relu')(d)\n",
        "            d = BatchNormalization(momentum=0.8)(d)\n",
        "            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
        "            d = BatchNormalization(momentum=0.8)(d)\n",
        "            d = Add()([d, layer_input])\n",
        "            return d\n",
        "\n",
        "        def deconv2d(layer_input):\n",
        "            \"\"\"Layers used during upsampling\"\"\"\n",
        "            u = UpSampling2D(size=2)(layer_input)\n",
        "            u = Conv2D(256, kernel_size=3, strides=1, padding='same')(u)\n",
        "            u = Activation('relu')(u)\n",
        "            return u\n",
        "\n",
        "        gen_input = Input(shape=self.input_shape)\n",
        "\n",
        "        # Pre-residual block\n",
        "        c1 = Conv2D(64, kernel_size=9, strides=1, padding='same')(gen_input)\n",
        "        c1 = Activation('relu')(c1)\n",
        "\n",
        "        # Propogate through residual blocks\n",
        "        r = residual_block(c1, self.gf)\n",
        "        for _ in range(self.n_residual_blocks - 1):\n",
        "            r = residual_block(r, self.gf)\n",
        "\n",
        "        # Post-residual block\n",
        "        c2 = Conv2D(64, kernel_size=3, strides=1, padding='same')(r)\n",
        "        c2 = BatchNormalization(momentum=0.8)(c2)\n",
        "        c2 = Add()([c2, c1])\n",
        "\n",
        "        # Upsampling\n",
        "        upsampling_hierarchy = [c2]\n",
        "        for ul in range(self.upsampling_levels):\n",
        "            upsampling_hierarchy.append(deconv2d(upsampling_hierarchy[-1]))\n",
        "\n",
        "        gen_output = Conv2D(self.channels, \n",
        "            kernel_size=9, strides=1, padding='same', activation='tanh')(upsampling_hierarchy[-1])\n",
        "\n",
        "        generator = Model(inputs=gen_input, outputs=gen_output)\n",
        "        generator.compile(loss='mse', optimizer=self.optimizer)\n",
        "        return generator\n",
        "\n",
        "    def get_gan(self, discriminator, generator):\n",
        "        \"\"\"\n",
        "        Builds the combined model of generator and discriminator\n",
        "        \"\"\"\n",
        "        \n",
        "        source_img = Input(shape=self.input_shape)\n",
        "        target_img = Input(shape=self.shape)\n",
        "\n",
        "        #generate fake image\n",
        "        fake_target = generator(source_img)\n",
        "        #generate features of the fake image\n",
        "        fake_features = self.vgg(fake_target)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        discriminator.trainable = False\n",
        "\n",
        "        # Discriminator determines validity of the generated images\n",
        "        validity = discriminator(fake_target)\n",
        "\n",
        "        #build the model\n",
        "        gan = Model([source_img, target_img], [validity, fake_features])\n",
        "        gan.compile(loss=['binary_crossentropy', 'mse'],\n",
        "                              loss_weights=[1e-4, 1],\n",
        "                              optimizer=self.optimizer)\n",
        "        return gan\n",
        "\n",
        "    def train(self, data_loader, epochs=1000, batch_size=1, save_interval=5):\n",
        "\n",
        "        print(\"Training\")\n",
        "\n",
        "        start_time = datetime.datetime.now()\n",
        "        for epoch in range(epochs):\n",
        "            # ----------------------\n",
        "            #  Train Discriminator\n",
        "            # ----------------------\n",
        "\n",
        "            self.discriminator.trainable = True\n",
        "    \n",
        "            # Sample images\n",
        "            source_img, target_img = data_loader.load_data(batch_size)\n",
        "\n",
        "            #generate fake target\n",
        "            fake_target = self.generator.predict(source_img)\n",
        "\n",
        "            # Train the discriminators (original images = real / generated = Fake)\n",
        "            valid = np.ones((batch_size,) + self.disc_patch)\n",
        "            fake = np.zeros((batch_size,) + self.disc_patch)\n",
        "            d_loss_real = self.discriminator.train_on_batch(target_img, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(fake_target, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # ------------------\n",
        "            #  Train Generator\n",
        "            # ------------------\n",
        "\n",
        "            self.discriminator.trainable = False\n",
        "            \n",
        "            # Sample images\n",
        "            source_img, target_img = data_loader.load_data(batch_size)\n",
        "\n",
        "            # The generator wants the discriminators to label the generated images as real\n",
        "            valid = np.ones((batch_size,) + self.disc_patch)\n",
        "           \n",
        "            # Extract ground truth image features using pre-trained VGG19 model\n",
        "            image_features = self.vgg.predict(target_img)\n",
        "\n",
        "            # Train the generator\n",
        "            g_loss = self.gan.train_on_batch([source_img, target_img], [valid, image_features])\n",
        "\n",
        "            elapsed_time = datetime.datetime.now() - start_time\n",
        "\n",
        "            # Plot the progress\n",
        "            print (\"Epoch %d,  time: %s, D-loss: %f, G1-loss: %f, G2-loss: %f\" % (epoch+1, elapsed_time, d_loss, g_loss[0], g_loss[1]))\n",
        "\n",
        "            # If at save interval => save model\n",
        "            if epoch % save_interval == 0:\n",
        "                self.save(epoch+1)\n",
        "\n",
        "    def save(self, filePrefix):\n",
        "        os.makedirs('models/{}', exist_ok=True)\n",
        "        self.discriminator.save_weights('models/{}.dsc.h5'.format(filePrefix))\n",
        "        self.generator.save_weights('models/{}.gen.h5'.format(filePrefix))\n",
        "        self.gan.save_weights('models/{}.gan.h5'.format(filePrefix))\n",
        "    \n",
        "    def load(self, filePrefix):\n",
        "        print (\"Loading models.\")\n",
        "        self.discriminator.load_weights('models/{}.dsc.h5'.format(filePrefix))\n",
        "        self.generator.load_weights('models/{}.gen.h5'.format(filePrefix))\n",
        "        self.gan.load_weights('models/{}.gan.h5'.format(filePrefix))\n",
        "\n",
        "    def predict(self, data_loader, file_name, output_file):\n",
        "        print (\"Predicting..\")\n",
        "        imgs_src = data_loader.single_img(file_name)\n",
        "        imgs_fk = self.generator.predict(imgs_src).reshape(self.height, self.width)\n",
        "        Image.fromarray(((imgs_fk + 1)*127.5).astype(np.uint8), mode='L').save(output_file)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RoJ02eAApRKo"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yrnibKw6pOYZ",
        "colab": {}
      },
      "source": [
        "input_size = (128, 128)\n",
        "output_size = (512, 512)\n",
        "\n",
        "dl = DataLoader()\n",
        "deconvgan = SRGAN(input_size, output_size)\n",
        "deconvgan.train(dl, epochs=10, batch_size=1, save_interval=100)\n",
        "#deconvgan.train(dl, epochs=3000, batch_size=1, save_interval=100)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rGPwENes18IV",
        "colab": {}
      },
      "source": [
        "#!mkdir models\n",
        "#!gdown https://drive.google.com/uc?id=1rX2lO9a9KZ-AUnZ7XV65_-tp6kSEvdS6\n",
        "#!unzip gan.zip\n",
        "#!mv *.h5 models/\n",
        "#dl = DataLoader()\n",
        "#deconvgan.load('3000')\n",
        "\n",
        "from PIL import Image\n",
        "deconvgan.predict(dl, 'sres/test/source/0.png', '0-pred.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "agx6XP8nbM4b",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image('sres/test/source/0.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ef_FEdCbiYr",
        "colab": {}
      },
      "source": [
        "Image('0-pred.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p3QBZ8PFblNu",
        "colab": {}
      },
      "source": [
        "Image('sres/test/target/0.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
