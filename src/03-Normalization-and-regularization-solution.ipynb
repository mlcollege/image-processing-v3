{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-Normalization-and-regularization-solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W38AS1bbMSAB"
      },
      "source": [
        "# Normalization and regularization techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRvEGyli-o16"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "We will experiment with [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) data set. It is similar to well known MNIST data set but a bit more difficult to classify. It consists of clothing classes. The data is already shuffled and split to train and test parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffslWOEb-pmu",
        "outputId": "0000214c-0850-4a17-e0f0-84e3ee06559d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pickle\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(\"X_train original shape: {}\".format(X_train.shape))\n",
        "print(\"y_train original shape: {}\".format(y_train.shape))\n",
        "print(\"X_test original shape: {}\".format(X_test.shape))\n",
        "print(\"y_test original shape: {}\".format(y_test.shape))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train original shape: (60000, 28, 28)\n",
            "y_train original shape: (60000,)\n",
            "X_test original shape: (10000, 28, 28)\n",
            "y_test original shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm92Tbbi-ySC"
      },
      "source": [
        "Look at one random example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVelrCku-uiR",
        "outputId": "c1c83ef4-38f5-4a14-9446-f61aa2bc1247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "i=3495\n",
        "\n",
        "#print(X_train[i])\n",
        "plt.imshow(X_train[i], cmap='gray')\n",
        "plt.title(\"Class {}\".format(y_train[i]))\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wIkgz7X-44q"
      },
      "source": [
        "## Transform the data\n",
        "\n",
        "We need to scale the input values to have the range (0,1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo58moqt-0r0"
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGM3Camr_D5l"
      },
      "source": [
        "Reshape to 3d tensors (width, height, channels)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RntHN3GZ_EWA",
        "outputId": "63a37023-cc4f-4146-9581-aed8e3c4b908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train3d = X_train.reshape(60000, 28, 28, 1)\n",
        "X_test3d = X_test.reshape(10000, 28, 28, 1)\n",
        "print(\"X_train matrix shape: {}\".format(X_train3d.shape))\n",
        "print(\"X_test matrix shape: {}\".format(X_test3d.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train matrix shape: (60000, 28, 28, 1)\n",
            "X_test matrix shape: (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jaa13K4_LWy"
      },
      "source": [
        "Transform the targets into one-hot encoding, i.e.\n",
        "\n",
        "\n",
        "```\n",
        "0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "```\n",
        "etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEuuEd5N_GhB",
        "outputId": "d50d2f62-8e6d-4792-be99-2a4d74213308",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "n_classes = 10\n",
        "\n",
        "print(y_train[49])\n",
        "\n",
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_test = to_categorical(y_test, n_classes)\n",
        "\n",
        "print(y_train[49])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ_yK58i_Ucc"
      },
      "source": [
        "## Architecture definition\n",
        "\n",
        "This is a simple functional model for the classification problem. Your tasks are:\n",
        "1. Implement [Batch](https://keras.io/api/layers/normalization_layers/batch_normalization/) and [Layer](https://keras.io/api/layers/normalization_layers/layer_normalization/) normalization and compare the accuracies.\n",
        "2. Experiment with [L2 regularization](https://keras.io/api/layers/regularizers/) and [dropout](https://keras.io/api/layers/regularization_layers/dropout/). Try to maximize the validation accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mISOO8tQ_ved"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, BatchNormalization, Flatten, Dropout, Dense, Activation, BatchNormalization, LayerNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "#Define input of the Neural Network\n",
        "visible = Input(shape=(28, 28, 1, ))\n",
        "\n",
        "#convolution 1st layer\n",
        "conv1 = Conv2D(64, kernel_size=(3,3), padding=\"same\")(visible)\n",
        "activ1 = Activation('relu')(conv1)\n",
        "bn1 = BatchNormalization()(activ1)\n",
        "drop1 = Dropout(0.25)(bn1)\n",
        "\n",
        "#convolution 2nd layer\n",
        "conv2 = Conv2D(64, kernel_size=(3,3), padding=\"same\")(drop1)\n",
        "activ2 = Activation('relu')(conv2)\n",
        "bn2 = BatchNormalization()(activ2)\n",
        "pool2 = MaxPooling2D()(bn2)\n",
        "drop2 = Dropout(0.25)(pool2)\n",
        "\n",
        "#convolution 3rd layer\n",
        "conv3 = Conv2D(64, kernel_size=(3,3), padding=\"same\")(drop2)\n",
        "activ3 = Activation('relu')(conv3)\n",
        "bn3 = BatchNormalization()(activ3)\n",
        "pool3 = MaxPooling2D()(bn3)\n",
        "drop3 = Dropout(0.25)(pool3)\n",
        "\n",
        "#fully connected 4th layer\n",
        "flat4 = Flatten()(drop3)\n",
        "dense4 = Dense(500)(flat4)\n",
        "bn4 = BatchNormalization()(dense4)\n",
        "activ4 = Activation('relu')(bn4)\n",
        "drop4 = Dropout(0.25)(activ4)\n",
        "\n",
        "#fully connected 5th layer\n",
        "dense5 = Dense(10)(drop4)\n",
        "output = Activation('softmax')(dense5)\n",
        "\n",
        "model = Model(inputs=visible, outputs=output)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMvSl5erbuEg"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "#print(model.summary())\n",
        "#plot_model(model)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBwd1WqbO03N"
      },
      "source": [
        "Compile and the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ux0mm1_2VO"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrmhiUZfAIOy",
        "outputId": "5459a31e-8d26-48cf-cfd9-afa8c17bceb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train3d, y_train,\n",
        "          batch_size = 128, epochs = 100, verbose=1,\n",
        "          validation_data=(X_test3d, y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 25s 27ms/step - loss: 0.3931 - accuracy: 0.8577 - val_loss: 1.6304 - val_accuracy: 0.5807\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.2620 - accuracy: 0.9033 - val_loss: 0.2524 - val_accuracy: 0.9085\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.2248 - accuracy: 0.9177 - val_loss: 0.2234 - val_accuracy: 0.9184\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1998 - accuracy: 0.9260 - val_loss: 0.2051 - val_accuracy: 0.9230\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1801 - accuracy: 0.9340 - val_loss: 0.2053 - val_accuracy: 0.9282\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.1646 - accuracy: 0.9390 - val_loss: 0.1941 - val_accuracy: 0.9286\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 11s 22ms/step - loss: 0.1504 - accuracy: 0.9432 - val_loss: 0.1971 - val_accuracy: 0.9296\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1378 - accuracy: 0.9491 - val_loss: 0.1864 - val_accuracy: 0.9358\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.1292 - accuracy: 0.9516 - val_loss: 0.1949 - val_accuracy: 0.9344\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1154 - accuracy: 0.9568 - val_loss: 0.1846 - val_accuracy: 0.9369\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1058 - accuracy: 0.9602 - val_loss: 0.1928 - val_accuracy: 0.9341\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0975 - accuracy: 0.9631 - val_loss: 0.2026 - val_accuracy: 0.9348\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0902 - accuracy: 0.9665 - val_loss: 0.2172 - val_accuracy: 0.9312\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0856 - accuracy: 0.9686 - val_loss: 0.1991 - val_accuracy: 0.9377\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0761 - accuracy: 0.9716 - val_loss: 0.2149 - val_accuracy: 0.9328\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.0717 - accuracy: 0.9736 - val_loss: 0.2152 - val_accuracy: 0.9382\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0661 - accuracy: 0.9750 - val_loss: 0.2163 - val_accuracy: 0.9352\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0639 - accuracy: 0.9762 - val_loss: 0.2156 - val_accuracy: 0.9345\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0586 - accuracy: 0.9786 - val_loss: 0.2304 - val_accuracy: 0.9335\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0587 - accuracy: 0.9787 - val_loss: 0.2156 - val_accuracy: 0.9393\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0525 - accuracy: 0.9805 - val_loss: 0.2468 - val_accuracy: 0.9358\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0491 - accuracy: 0.9818 - val_loss: 0.2290 - val_accuracy: 0.9376\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0481 - accuracy: 0.9827 - val_loss: 0.2349 - val_accuracy: 0.9370\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0461 - accuracy: 0.9828 - val_loss: 0.2628 - val_accuracy: 0.9318\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0445 - accuracy: 0.9841 - val_loss: 0.2329 - val_accuracy: 0.9394\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0392 - accuracy: 0.9856 - val_loss: 0.2457 - val_accuracy: 0.9359\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0390 - accuracy: 0.9861 - val_loss: 0.2450 - val_accuracy: 0.9386\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0375 - accuracy: 0.9871 - val_loss: 0.2450 - val_accuracy: 0.9358\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0335 - accuracy: 0.9877 - val_loss: 0.2494 - val_accuracy: 0.9389\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0346 - accuracy: 0.9875 - val_loss: 0.2435 - val_accuracy: 0.9371\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0342 - accuracy: 0.9878 - val_loss: 0.2634 - val_accuracy: 0.9362\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0348 - accuracy: 0.9874 - val_loss: 0.2572 - val_accuracy: 0.9362\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.0324 - accuracy: 0.9880 - val_loss: 0.2665 - val_accuracy: 0.9378\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0296 - accuracy: 0.9892 - val_loss: 0.2621 - val_accuracy: 0.9371\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.2612 - val_accuracy: 0.9376\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 0.2522 - val_accuracy: 0.9394\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0269 - accuracy: 0.9905 - val_loss: 0.2624 - val_accuracy: 0.9377\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.2588 - val_accuracy: 0.9403\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 11s 22ms/step - loss: 0.0259 - accuracy: 0.9911 - val_loss: 0.2636 - val_accuracy: 0.9399\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0254 - accuracy: 0.9912 - val_loss: 0.2571 - val_accuracy: 0.9399\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.2706 - val_accuracy: 0.9381\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0223 - accuracy: 0.9920 - val_loss: 0.2725 - val_accuracy: 0.9364\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.2805 - val_accuracy: 0.9374\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.2691 - val_accuracy: 0.9368\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 0.2926 - val_accuracy: 0.9368\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 11s 22ms/step - loss: 0.0232 - accuracy: 0.9917 - val_loss: 0.2794 - val_accuracy: 0.9387\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.2703 - val_accuracy: 0.9367\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.2741 - val_accuracy: 0.9391\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.2846 - val_accuracy: 0.9376\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.3082 - val_accuracy: 0.9378\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0198 - accuracy: 0.9927 - val_loss: 0.3167 - val_accuracy: 0.9338\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 0.2729 - val_accuracy: 0.9365\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.2834 - val_accuracy: 0.9397\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 0.2925 - val_accuracy: 0.9401\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0193 - accuracy: 0.9930 - val_loss: 0.2744 - val_accuracy: 0.9389\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.2929 - val_accuracy: 0.9380\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.2991 - val_accuracy: 0.9391\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.2839 - val_accuracy: 0.9392\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.3012 - val_accuracy: 0.9384\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 0.3342 - val_accuracy: 0.9341\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 11s 22ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.3023 - val_accuracy: 0.9381\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0164 - accuracy: 0.9941 - val_loss: 0.3021 - val_accuracy: 0.9363\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0156 - accuracy: 0.9943 - val_loss: 0.2949 - val_accuracy: 0.9384\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.3168 - val_accuracy: 0.9369\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.2992 - val_accuracy: 0.9372\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.2930 - val_accuracy: 0.9362\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.2966 - val_accuracy: 0.9390\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.3082 - val_accuracy: 0.9395\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.2916 - val_accuracy: 0.9366\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.3364 - val_accuracy: 0.9360\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.3195 - val_accuracy: 0.9354\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.3107 - val_accuracy: 0.9379\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 0.3088 - val_accuracy: 0.9379\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.3052 - val_accuracy: 0.9403\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 11s 22ms/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.3105 - val_accuracy: 0.9359\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.3261 - val_accuracy: 0.9340\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0138 - accuracy: 0.9949 - val_loss: 0.3182 - val_accuracy: 0.9382\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.3175 - val_accuracy: 0.9382\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.0129 - accuracy: 0.9955 - val_loss: 0.3217 - val_accuracy: 0.9358\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.3165 - val_accuracy: 0.9394\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.3141 - val_accuracy: 0.9393\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.3260 - val_accuracy: 0.9360\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 0.3188 - val_accuracy: 0.9378\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.3130 - val_accuracy: 0.9398\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.3061 - val_accuracy: 0.9400\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.3250 - val_accuracy: 0.9386\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.3216 - val_accuracy: 0.9395\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.3203 - val_accuracy: 0.9372\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.3128 - val_accuracy: 0.9395\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.3186 - val_accuracy: 0.9393\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.3292 - val_accuracy: 0.9387\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.3308 - val_accuracy: 0.9359\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.2923 - val_accuracy: 0.9414\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.3213 - val_accuracy: 0.9411\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.3153 - val_accuracy: 0.9405\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.3096 - val_accuracy: 0.9428\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.3245 - val_accuracy: 0.9406\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.3166 - val_accuracy: 0.9393\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.3329 - val_accuracy: 0.9410\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.3165 - val_accuracy: 0.9407\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d6e6d767d00>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}